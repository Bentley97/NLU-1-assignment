{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FirstAssignment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNHFMEpdp/9ayMOb5I1p53+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bentley97/NLU_First_assignment/blob/main/FirstAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWWgrJ7wRxTu"
      },
      "source": [
        "**FIRST ASSIGNMENT**\n",
        "\n",
        "Student:\n",
        "*   Name: Luca\n",
        "*   Surname: Bentivoglio\n",
        "*   Student number: 221246\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I50Ll8o8U8TE"
      },
      "source": [
        "**REQUIREMENTS**\n",
        "\n",
        "If you open the notebook, is sufficient to run the first block of code to import spaCy, define a sentence for tests and load the dependency parsing model.\n",
        "Then you can run each function with its test calls."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrieWP0k6tnq"
      },
      "source": [
        "import spacy\n",
        "\n",
        "test_sentence = \"I saw a man with a telescope.\"\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-PkeTbma8yZ"
      },
      "source": [
        "**FUNCTION 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq4wKemN6MTT"
      },
      "source": [
        "def extract_dependency_path(sentence):\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  paths = []\n",
        "\n",
        "  for token in doc:\n",
        "    token_path = []\n",
        "\n",
        "    while token != token.head:  #we can use also (token != token.sent.root)\n",
        "      token_path.insert(0, token.text)\n",
        "      #token_path.insert(0, \"goes with dep '\"+token.dep_+\"' in\")\n",
        "      token_path.insert(0, \"--\"+token.dep_+\"->\")\n",
        "      token = token.head\n",
        "\n",
        "    token_path.insert(0, token.text)\n",
        "    #token_path.insert(0, \"goes with dep '\"+token.dep_+\"' in\")\n",
        "    token_path.insert(0, \"--\"+token.dep_+\"->\")\n",
        "    token_path.insert(0, \"ROOT\")\n",
        "    paths.append(token_path)\n",
        "  \n",
        "  return paths\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUhfyCNlaqps",
        "outputId": "cfcc5a76-2ac6-4fbb-b881-cc938eccaf79"
      },
      "source": [
        "### TEST ###\n",
        "dep_paths = extract_dependency_path(test_sentece)\n",
        "\n",
        "for dep_path in dep_paths:\n",
        "  print(\"The dependency path for token '{}'\\tis:\\t{}\".format(dep_path[-1],dep_path).expandtabs(15))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dependency path for token 'I'            is:            ['ROOT', '--ROOT->', 'saw', '--nsubj->', 'I']\n",
            "The dependency path for token 'saw'          is:            ['ROOT', '--ROOT->', 'saw']\n",
            "The dependency path for token 'a'            is:            ['ROOT', '--ROOT->', 'saw', '--dobj->', 'man', '--det->', 'a']\n",
            "The dependency path for token 'man'          is:            ['ROOT', '--ROOT->', 'saw', '--dobj->', 'man']\n",
            "The dependency path for token 'with'         is:            ['ROOT', '--ROOT->', 'saw', '--dobj->', 'man', '--prep->', 'with']\n",
            "The dependency path for token 'a'            is:            ['ROOT', '--ROOT->', 'saw', '--dobj->', 'man', '--prep->', 'with', '--pobj->', 'telescope', '--det->', 'a']\n",
            "The dependency path for token 'telescope'    is:            ['ROOT', '--ROOT->', 'saw', '--dobj->', 'man', '--prep->', 'with', '--pobj->', 'telescope']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY7NFqi-ayhp"
      },
      "source": [
        "**FUNCTION 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ne2jh62axs8"
      },
      "source": [
        "def extract_subtrees(sentence):\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  result = []\n",
        "  \n",
        "  for token in doc:\n",
        "    subtree_list = []\n",
        "    for element in token.subtree:\n",
        "      if element != token:\n",
        "        subtree_list.append(element)\n",
        "    result.append([token, subtree_list])\n",
        "\n",
        "  return result  #returns a list of elements, each composed by the token and the list of its dependents in its subtree(without himself) ordered w.r.t. sentence order  (usare elenco puntato per spiegare meglio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IodsDpSjnpeN",
        "outputId": "8a612ae0-064d-440b-ac5c-50ef33656729"
      },
      "source": [
        "subtrees = extract_subtrees(test_sentence)\n",
        "\n",
        "for t,s in subtrees:\n",
        "  #print(s)\n",
        "  print(\"Token: {}\\t{}\".format(t,s).expandtabs(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token: I            []\n",
            "Token: saw          [I, a, man, with, a, telescope]\n",
            "Token: a            []\n",
            "Token: man          [a, with, a, telescope]\n",
            "Token: with         [a, telescope]\n",
            "Token: a            []\n",
            "Token: telescope    [a]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg7vogKaqBoL"
      },
      "source": [
        "**FUNCTION 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzcZeoMrqE5P"
      },
      "source": [
        "def is_equal(tokenList, stringList):  #check equality between elements of a list of tokens and a list of strings\n",
        "  if len(tokenList) != len(stringList):\n",
        "    return False\n",
        "\n",
        "  for i in range(len(tokenList)):\n",
        "    if tokenList[i].text != stringList[i]:\n",
        "      return False\n",
        "  \n",
        "  return True\n",
        "\n",
        "def is_subtree(sentence, segment): #segment => ordered list of words from a sentence\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  for token in doc:\n",
        "    subtree = token.subtree\n",
        "    if(is_equal(list(subtree), segment)):\n",
        "        return True\n",
        "\n",
        "  return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjSLuyZUvZl2",
        "outputId": "06c23caa-29e1-4f05-8745-18e9413a7b8a"
      },
      "source": [
        "input_segment = [\"a\",\"man\",\"with\",\"a\",\"telescope\"]\n",
        "input_segment2 = [\"a\",\"man\"]\n",
        "input_segment3 = [\"with\",\"a\",\"telescope\"]\n",
        "\n",
        "\n",
        "print(\"Sentence:\\t{}\".format(test_sentence))\n",
        "print(\"Segment:\\t{}\".format(input_segment3))\n",
        "print(is_subtree(test_sentence, input_segment3))\n",
        "\n",
        "\n",
        "#print(list(input_segment)==list(input_segment3))\n",
        "#print(type(input_segment))\n",
        "#print(is_subtree(test_sentence, input_segment))\n",
        "#print(is_subtree(test_sentence, input_segment2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence:\tI saw a man with a telescope\n",
            "Segment:\t['with', 'a', 'telescope']\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kgar-tpn3-F"
      },
      "source": [
        "**FUNCTION 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMNwSYyFn3hk"
      },
      "source": [
        "def get_head(span):     #identify head of a span\n",
        "  doc = nlp(span)\n",
        "\n",
        "  return [token for token in doc if token.head == token][0]   # the condition can be changed with (token.dep_ == 'ROOT')      we can use also Span object of spacy\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UexIDRuGxH9j",
        "outputId": "bed2611d-0703-4a12-b1d9-cb5ed7966f02"
      },
      "source": [
        "span1 = \"Give it to me! Right now.\"   #to test return single word \n",
        "print(get_head(span1))\n",
        "\n",
        "span2 = \"boowling water bad under down mountain\"\n",
        "print(get_head(span2))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Give\n",
            "water\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BObFGeUyhBc"
      },
      "source": [
        "**FUNCTION 5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqSedXP7ygns"
      },
      "source": [
        "def extract_spans(sentence):\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  span_dict = {\n",
        "      'nsubj':[],\n",
        "      'dobj':[],\n",
        "      'iobj':[]\n",
        "  }\n",
        "\n",
        "  for token in doc:\n",
        "    if token.dep_ == 'nsubj' or token.dep_ == 'dobj' or token.dep_ == 'iobj':\n",
        "      for descendant in token.subtree:                    # instead of cycle on elements of the subtree we can use left_edge and right_edge attributes that gives directly first and last element of the token's subtree\n",
        "        span_dict[token.dep_].append(descendant.text)     #span_dict[token.dep_] = doc[token.left_edge.i : token.right_edge.i+1]\n",
        "  \n",
        "  return span_dict\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrkkEY_ZASBM",
        "outputId": "ef5c7be5-b8e6-4e97-b7dc-43a5aa161387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentence = \"I saw a man with a telescope.\"\n",
        "\n",
        "spans = extract_spans(sentence)\n",
        "\n",
        "for item in spans.items():\n",
        "  print(item)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('nsubj', ['I'])\n",
            "('dobj', ['a', 'man', 'with', 'a', 'telescope'])\n",
            "('iobj', [])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}